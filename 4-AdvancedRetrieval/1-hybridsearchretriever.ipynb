{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083868fe",
   "metadata": {},
   "source": [
    "## Hybrid Retriever- Combining Dense And Sparse Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ccbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77955e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullah/Repositories/learning/rag-and-agentic-ai/udemy-rag-course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain helps build LLM applications.\"),\n",
    "    Document(page_content=\"Pinecone is a vector database for semantic search.\"),\n",
    "    Document(page_content=\"The Eiffel Tower is located in Paris.\"),\n",
    "    Document(page_content=\"Langchain can be used to develop agentic ai application.\"),\n",
    "    Document(page_content=\"Langchain has many types of retrievers.\")\n",
    "]\n",
    "\n",
    "# Step 2: Dense Retriever (FAISS + HuggingFace)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "dense_retriever = dense_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f55327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sparse Retriever(BM25)\n",
    "sparse_retriever=BM25Retriever.from_documents(docs)\n",
    "sparse_retriever.k=3 ##top- k documents to retriever\n",
    "\n",
    "## step 4 : Combine with Ensemble Retriever\n",
    "hybrid_retriever=EnsembleRetriever(\n",
    "    retrievers=[dense_retriever,sparse_retriever],\n",
    "    weight=[0.7,0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb470b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1213fc050>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x1213fe570>, k=3)], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d705557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Document 1:\n",
      "LangChain helps build LLM applications.\n",
      "\n",
      "üîπ Document 2:\n",
      "Langchain can be used to develop agentic ai application.\n",
      "\n",
      "üîπ Document 3:\n",
      "Langchain has many types of retrievers.\n",
      "\n",
      "üîπ Document 4:\n",
      "Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Query and get results\n",
    "query = \"How can I build an application using LLMs?\"\n",
    "results = hybrid_retriever.invoke(query)\n",
    "\n",
    "# Step 6: Print results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nüîπ Document {i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03c358",
   "metadata": {},
   "source": [
    "### RAG Pipeline with hybrid retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082e92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac16f534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x134c57410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x134c570b0>, root_client=<openai.OpenAI object at 0x134c56e40>, root_async_client=<openai.AsyncOpenAI object at 0x134c57500>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Prompt Template\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "## step 6-llm\n",
    "llm=init_chat_model(\"openai:gpt-5\",temperature=0.2)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e8e663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1213fc050>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x1213fe570>, k=3)], weights=[0.5, 0.5]), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x134c57410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x134c570b0>, root_client=<openai.OpenAI object at 0x134c56e40>, root_async_client=<openai.AsyncOpenAI object at 0x134c57500>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create stuff Docuemnt Chain\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=prompt)\n",
    "\n",
    "## create Full rAg chain\n",
    "rag_chain=create_retrieval_chain(retriever=hybrid_retriever,combine_docs_chain=document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991be9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Answer:\n",
      " Here‚Äôs a practical path based on the tools in your context:\n",
      "\n",
      "1) Pick an approach\n",
      "- Retrieval-Augmented Generation (RAG): Great for Q&A or chat over your data.\n",
      "- Agentic app: Let the model choose actions/tools (e.g., search your data, call APIs) to achieve goals.\n",
      "\n",
      "2) Set up the core stack with LangChain\n",
      "- LangChain: Orchestrates prompts, chains, agents, and retrievers.\n",
      "- Pinecone: Stores vector embeddings for semantic search.\n",
      "- Retriever: Use a LangChain retriever (e.g., a vector-store retriever backed by Pinecone). LangChain offers many retriever types; you can start with a standard vector retriever and iterate.\n",
      "\n",
      "3) Build a RAG flow (baseline)\n",
      "- Ingest: Chunk your documents, embed them, and upsert vectors into a Pinecone index.\n",
      "- Retrieve: Wrap Pinecone with a LangChain retriever to fetch top-k relevant chunks for a user question.\n",
      "- Generate: Create a LangChain chain that:\n",
      "  - Takes the user question\n",
      "  - Retrieves context via the retriever\n",
      "  - Injects that context into a prompt\n",
      "  - Calls your chosen LLM to produce the answer\n",
      "- Add response guidelines in the prompt (cite sources, be concise, say ‚ÄúI don‚Äôt know‚Äù if needed).\n",
      "\n",
      "4) Upgrade to an agentic app (optional)\n",
      "- Define tools the agent can use: e.g., a Pinecone retriever tool, simple calculators, or API callers.\n",
      "- Use a LangChain agent to plan-and-act: the LLM decides when to call the Pinecone retriever, when to reason, and when to answer.\n",
      "- Useful when tasks require multiple steps or decisions beyond a single RAG call.\n",
      "\n",
      "5) Quality and iteration\n",
      "- Tune chunking size and top-k retrieval for relevance.\n",
      "- Experiment with different LangChain retriever types (e.g., multi-step or re-ranking variants) if needed.\n",
      "- Add caching and simple guards (max context length, refusal policies, source attribution).\n",
      "\n",
      "6) Ship it\n",
      "- Wrap your chain/agent behind an API endpoint.\n",
      "- Add a lightweight UI chat box that sends user queries to the chain/agent and displays answers plus retrieved snippets.\n",
      "- Monitor latency (index size, top-k) and accuracy (spot-check answers with sources).\n",
      "\n",
      "This gives you a straightforward RAG app using LangChain + Pinecone, with a clear path to agentic behavior when you need tool use and multi-step reasoning.\n",
      "\n",
      "üìÑ Source Documents:\n",
      "\n",
      "Doc 1: LangChain helps build LLM applications.\n",
      "\n",
      "Doc 2: Langchain can be used to develop agentic ai application.\n",
      "\n",
      "Doc 3: Langchain has many types of retrievers.\n",
      "\n",
      "Doc 4: Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Ask a question\n",
    "query = {\"input\": \"How can I build an app using LLMs?\"}\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# Step 10: Output\n",
    "print(\"‚úÖ Answer:\\n\", response[\"answer\"])\n",
    "\n",
    "print(\"\\nüìÑ Source Documents:\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\"\\nDoc {i+1}: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08942fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
